{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Video Detection\n",
    "\n",
    "## <a id='0'>Content</a>\n",
    "\n",
    "- <a href='#1'>Introduction</a>  \n",
    "- <a href='#2'>Preliminary data exploration</a>  \n",
    "    * Load the packages  \n",
    "    * Load the data  \n",
    "    * Check files type  \n",
    "- <a href='#5'>Face detection</a>  \n",
    "- <a href='#6'>Resources</a> \n",
    "- <a href='#7'>References</a>     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='2'>Introduction</a>\n",
    "\n",
    "**Deepfake**, derived from \"Deep Learning\" and \"Fake,\" refers to the technology of taking one person's likeness from an image or video  \n",
    "and replacing it with another's using Deep Artificial Neural Networks. Major companies invest heavily in combating DeepFakes to counter  \n",
    "this threat. DeepFake is rapidly invading the film industry and threatens to compromise news agencies. Large digital companies, including  \n",
    "content providers and social platforms, are at the forefront of fighting DeepFakes. GANs (Generative Adversarial Networks) that generate  \n",
    "DeepFakes are improving daily. \n",
    "\n",
    "In the **Data Exploration** section, we perform a partial Exploratory Data Analysis (EDA) on the training and testing data. After checking  \n",
    "the file types, we focus first on the **metadata** files, exploring them in detail after importing them into dataframes. We then explore  \n",
    "video files by examining a sample of fake videos followed by real videos. Additionally, we analyze a few videos with the same origin, visualizing  \n",
    "one frame from both real and fake videos and playing a few videos. \n",
    "\n",
    "Next, we perform face (and other objects from the persons in the videos) extraction using OpenCV Haar Cascade resources to identify frontal faces,  \n",
    "eyes, smiles, and profile faces from still images in the videos.\n",
    "\n",
    "In the **Resources** section, There is a short list of various resources for GAN and DeepFake, including blog  \n",
    "posts, Kaggle Kernels, and GitHub repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2'>Preliminary data exploration</a>\n",
    "\n",
    "### Datasets:\n",
    "There are 4 groups of datasets associated with this competition.\n",
    "\n",
    "1. **Training Set: This dataset containing labels for the target.**  \n",
    "2. **Public Validation Set:** We trained our data using a small set of 400 videos/ids contained within this Public Validation Set.  \n",
    "This is available on the Kaggle Data page as test_videos.zip  \n",
    "3. **Public Test Set:**   \n",
    "Our code is running this on Public Test Set. When the re-run is complete, the score will be displayed.  \n",
    "4. **Private Test Set:**\n",
    "This dataset is privately held outside of Kaggle’s platform, and is used to compute the private leaderboard. It contains videos  \n",
    "with a similar format/nature as the Training & Public Validation/Test Sets, but are real, organic videos with and without deepfakes.  \n",
    "\n",
    "### Workflow:\n",
    "add more about the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation**\n",
    "$LogLoss = -\\frac{1}{n} \\sum_{1=1}^{n} \\left[ y_{i} \\log \\left( \\hat{y}_{i} \\right) + \\left(1 - y_{i}\\right) \\log \\left(1 - \\hat{y}_{i} \\right) \\right] \\ $\n",
    "\n",
    "where\n",
    "\n",
    "* $n$ is the number of videos being predicted\n",
    "* $\\hat{y}_{i}$ is the predicted probability of the video being FAKE\n",
    "* $y_{i}$ is 1 if the video is FAKE, 0 if REAL\n",
    "* $\\log( )$ is the natural (base e) logarithm = $\\ln(  )$\n",
    "\n",
    "A smaller log loss is better. The use of the logarithm provides extreme punishments for being both confident and wrong.  \n",
    "In the worst possible case, a prediction that something is true when it is actually false will add infinite to your error score.  \n",
    "In order to prevent this, predictions are bounded away from the extremes by a small value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "import matplotlib \n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt \n",
    "from typing import Optional\n",
    "import torch \n",
    "from torch.utils.data import DataLoader \n",
    "from tqdm.auto import tqdm \n",
    "import cv2 as cv \n",
    "import platform\n",
    "import subprocess\n",
    "import pyopencl as cl \n",
    "import tensorflow as tf \n",
    "import getpass\n",
    "import json\n",
    "from rocm.configure import * \n",
    "from utils.video_dataset import *\n",
    "from IPython.display import HTML \n",
    "from base64 import b64encode\n",
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.1\n",
      "3.9.19 | packaged by conda-forge | (main, Mar 20 2024, 12:38:46) [MSC v.1929 64 bit (AMD64)]\n",
      "Kernel mode driver status: \n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(sys.version)\n",
    "print(f'Kernel mode driver status: {subprocess.run(\"dkms status\", shell=True, capture_output=True, text=True).stdout}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATA_CONFIG = './configs/data_path.json'\n",
    "\n",
    "with open(DATA_CONFIG, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "ROOT_FOLDER = data['dataset'][getpass.getuser()][\"root\"]\n",
    "DATA_FOLDER = data['dataset'][getpass.getuser()][\"train_set\"]\n",
    "DATA_SAMPLE_FOLDER = data['dataset'][getpass.getuser()][\"data_sample\"]\n",
    "COMPRESSED_DATA_FOLDER = data['dataset'][getpass.getuser()][\"compressed\"]\n",
    "TRAIN_SAMPLE_FOLDER = data['dataset'][getpass.getuser()][\"train_sample\"]\n",
    "TEST_SAMPLE_FOLDER = data['dataset'][getpass.getuser()][\"test_videos\"]\n",
    "\n",
    "BATCH_SIZE = data['batch_size']\n",
    "DATA_DIRECTORIES = os.listdir(DATA_FOLDER)\n",
    "\n",
    "# LIBS\n",
    "FACE_DETECTION_FOLDER = 'input/haar-cascades-for-face-detection'\n",
    "RUN_OFFLINE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILITY FUNCTIONS\n",
    "\n",
    "# Function to display video\n",
    "def play_video(video_file, subset=TRAIN_SAMPLE_FOLDER):\n",
    "    '''\n",
    "    Display video\n",
    "    param: video_file - the name of the video file to display\n",
    "    param: subset - the folder where the video file is located (can be TRAIN_SAMPLE_FOLDER or TEST_Folder)\n",
    "    '''\n",
    "    video_url = open(os.path.join(DATA_SAMPLE_FOLDER, subset,video_file),'rb').read()\n",
    "    data_url = f\"data:video/mp4;base64,{b64encode(video_url).decode()}\"\n",
    "    return HTML(f\"\"\"<video width=500 controls><source src=\"{data_url}\" type=\"video/mp4\"></video>\"\"\")\n",
    "\n",
    "# Function to display image from a video\n",
    "def display_image_from_video(video_path):\n",
    "    '''\n",
    "    input: video_path - path for video\n",
    "    process:\n",
    "    1. perform a video capture from the video\n",
    "    2. read the image\n",
    "    3. display the image\n",
    "    '''\n",
    "    capture_image = cv.VideoCapture(video_path) \n",
    "    ret, frame = capture_image.read()\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "    ax.imshow(frame)\n",
    "# Function to get the OpenCL platform information\n",
    "def get_platform_info():\n",
    "    platforms = cl.get_platforms()\n",
    "    for platform in platforms:\n",
    "        devices = platform.get_devices()\n",
    "        print(f\"Platform Name: {platform.get_info(cl.platform_info.NAME)}\")\n",
    "        print(f\"Platform Vendor: {platform.get_info(cl.platform_info.VENDOR)}\")\n",
    "        print(f\"Platform Version: {platform.get_info(cl.platform_info.VERSION)}\")\n",
    "        print(f\"Platform Profile: {platform.get_info(cl.platform_info.PROFILE)}\")\n",
    "        for device in devices:\n",
    "            print(f\"Device: {device.name}\")\n",
    "\n",
    "    amd_platform = next(\n",
    "        (platform for platform in platforms if 'AMD' in platform.name), None\n",
    "    )\n",
    "\n",
    "# Function to check unique values in a dataset\n",
    "def unique_values(data):\n",
    "    total = data.count()\n",
    "    tt = pd.DataFrame(total)\n",
    "    tt.columns = ['Total']\n",
    "    uniques = []\n",
    "    for col in data.columns:\n",
    "        unique = data[col].nunique()\n",
    "        uniques.append(unique)\n",
    "    tt['Uniques'] = uniques\n",
    "    return(np.transpose(tt))\n",
    "\n",
    "# Function to check missing data in a dataset\n",
    "def missing_data(data):\n",
    "    total = data.isnull().sum()\n",
    "    percent = (data.isnull().sum()/data.isnull().count()*100)\n",
    "    tt = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    types = []\n",
    "    for col in data.columns:\n",
    "        dtype = str(data[col].dtype)\n",
    "        types.append(dtype)\n",
    "    tt['Types'] = types\n",
    "    return(np.transpose(tt))\n",
    "\n",
    "# Function to check the most frequent values in a dataset\n",
    "def most_frequent_values(data):\n",
    "    total = data.count()\n",
    "    tt = pd.DataFrame(total)\n",
    "    tt.columns = ['Total']\n",
    "    items = []\n",
    "    vals = []\n",
    "    for col in data.columns:\n",
    "        itm = data[col].value_counts().index[0]\n",
    "        val = data[col].value_counts().values[0]\n",
    "        items.append(itm)\n",
    "        vals.append(val)\n",
    "    tt['Most frequent item'] = items\n",
    "    tt['Frequency'] = vals\n",
    "    tt['Percent from total'] = np.round(vals / total * 100, 3)\n",
    "    return(np.transpose(tt))\n",
    "\n",
    "# Function to plot the count of classes in a dataset\n",
    "def plot_count(feature, title, df, size=1):\n",
    "    '''\n",
    "    Plot count of classes / feature\n",
    "    param: feature - the feature to analyze\n",
    "    param: title - title to add to the graph\n",
    "    param: df - dataframe from which we plot feature's classes distribution \n",
    "    param: size - default 1.\n",
    "    '''\n",
    "    f, ax = plt.subplots(1,1, figsize=(4*size,4))\n",
    "    total = float(len(df))\n",
    "    g = sns.countplot(x=feature, data=df, order=df[feature].value_counts().index[:20], palette='Set3', hue=feature, legend=False)\n",
    "    g.set_title(f\"Histogram of {title}\")\n",
    "    if(size > 2):\n",
    "        plt.xticks(rotation=90, size=8)\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        ax.text(p.get_x()+p.get_width()/2.,\n",
    "                height + 3,\n",
    "                '{:1.2f}%'.format(100*height/total),\n",
    "                ha=\"center\")\n",
    "    plt.show()\n",
    "\n",
    "# Function read video metadata from json files\n",
    "def read_meta_from_json(data_directories, data_folder, compressed_data_folder):\n",
    "    \n",
    "    meta_df = pd.DataFrame()\n",
    "\n",
    "    for index, part_folder in enumerate(data_directories):\n",
    "        part_path = os.path.join(data_folder, part_folder)\n",
    "        json_file = next(file for file in os.listdir(part_path) if file.endswith('json'))\n",
    "        json_file_path = os.path.join(part_path, json_file)\n",
    "        \n",
    "        part_df = pd.read_json(json_file_path).T\n",
    "        part_df['part'] = index\n",
    "        part_df['path'] = part_path\n",
    "        part_df['path-compressed'] =  os.path.join(compressed_data_folder, os.path.basename(part_path))\n",
    "        part_df['filename'] = part_df.index\n",
    "        \n",
    "        meta_df = pd.concat([meta_df, part_df])\n",
    "\n",
    "    # Display 5 random rows from meta_df\n",
    "    display(meta_df.sample(n=5))\n",
    "    return meta_df\n",
    "\n",
    "# Function to display image from a video\n",
    "def display_image_from_video_list(video_path_list, video_folder=TRAIN_SAMPLE_FOLDER):\n",
    "    '''\n",
    "    input: video_path_list - path for video\n",
    "    process:\n",
    "    0. for each video in the video path list\n",
    "        1. perform a video capture from the video\n",
    "        2. read the image\n",
    "        3. display the image\n",
    "    '''\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(2,3,figsize=(16,8))\n",
    "    # we only show images extracted from the first 6 videos\n",
    "    for i, video_file in enumerate(video_path_list[:6]):\n",
    "        video_path = os.path.join(DATA_SAMPLE_FOLDER, video_folder,video_file)\n",
    "        capture_image = cv.VideoCapture(video_path) \n",
    "        ret, frame = capture_image.read()\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        ax[i//3, i%3].imshow(frame)\n",
    "        ax[i//3, i%3].set_title(f\"Video: {video_file}\")\n",
    "        ax[i//3, i%3].axis('on')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add configurations for AMD GPU - Ubuntu only\n",
    "1. ADD rocm binary paths to the PATH environment variable.\n",
    "2. ADD open CL to LD_LIBRARY_PATH\n",
    "3. ADD user to \"render\" and \"video\" groups\n",
    "4. INSTALL clinfo\n",
    "5. INSTALL ocl-icd\n",
    "6. USE rocm-smi to check GPU's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Linux' and 'Ubuntu' in platform.version():\n",
    "    add_rocm_to_path()\n",
    "    add_ld_library_path()\n",
    "    check_user_in_groups()\n",
    "    install_clinfo()\n",
    "    install_ocl_icd()\n",
    "    rocm_smi()\n",
    "    clinfo()\n",
    "    rocminfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find physical devices (CPU and GPU)\n",
    "\n",
    "check that the cpu and gpu are recognized by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit GPU resource to enable resources for casual work\n",
    "\n",
    "TensorFlow allocates all of the GPU’s memory by default, leaving nothing for the desktop environment and any  \n",
    "other apps to use. In order to solve this issue, we save some resources aside for casual workload and maintenance resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform Name: AMD Accelerated Parallel Processing\n",
      "Platform Vendor: Advanced Micro Devices, Inc.\n",
      "Platform Version: OpenCL 2.1 AMD-APP (3592.0)\n",
      "Platform Profile: FULL_PROFILE\n",
      "Device: gfx1100\n"
     ]
    }
   ],
   "source": [
    "if gpus := tf.config.experimental.list_physical_devices('GPU'):\n",
    "  try:\n",
    "    get_platform_info()\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\datasets\\deepfake\\train_set\n",
      "Train samples: 401\n",
      "Test samples: 400\n"
     ]
    }
   ],
   "source": [
    "print(DATA_FOLDER)\n",
    "train_samples = os.listdir(os.path.join(DATA_SAMPLE_FOLDER, TRAIN_SAMPLE_FOLDER))\n",
    "test_samples = os.listdir(os.path.join(DATA_SAMPLE_FOLDER, TEST_SAMPLE_FOLDER))\n",
    "\n",
    "print(f\"Train samples: {len(train_samples)}\")\n",
    "print(f\"Test samples: {len(test_samples)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also added a face detection resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face detection resources: ['haarcascade_eye.xml', 'haarcascade_eye_tree_eyeglasses.xml', 'haarcascade_frontalface_alt.xml', 'haarcascade_frontalface_alt2.xml', 'haarcascade_frontalface_alt_tree.xml', 'haarcascade_frontalface_default.xml', 'haarcascade_fullbody.xml', 'haarcascade_profileface.xml', 'haarcascade_smile.xml', 'haarcascade_upperbody.xml']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Face detection resources: {os.listdir(FACE_DETECTION_FOLDER)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='5'>Face detection</a>  \n",
    "\n",
    "From [5] ([Face Detection using OpenCV](https://www.kaggle.com/serkanpeldek/face-detection-with-opencv)) by [@serkanpeldek](https://www.kaggle.com/serkanpeldek) we got and slightly modified the functions to extract face, profile face, eyes and smile.  \n",
    "\n",
    "The class ObjectDetector initialize the cascade classifier (using the imported resource). The function **detect** uses a method of the CascadeClassifier to detect objects into images - in this case the face, eye, smile or profile face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetector():\n",
    "    '''\n",
    "    Class for Object Detection\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,object_cascade_path):\n",
    "        '''\n",
    "        param: object_cascade_path - path for the *.xml defining the parameters for {face, eye, smile, profile}\n",
    "        detection algorithm\n",
    "        source of the haarcascade resource is: https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "        '''\n",
    "\n",
    "        self.objectCascade=cv.CascadeClassifier(object_cascade_path)\n",
    "\n",
    "\n",
    "    def detect(self, image, scale_factor=1.3, min_neighbors=5, min_size=(20,20)):\n",
    "        '''\n",
    "        Function return rectangle coordinates of object for given image\n",
    "        param: image - image to process\n",
    "        param: scale_factor - scale factor used for object detection\n",
    "        param: min_neighbors - minimum number of parameters considered during object detection\n",
    "        param: min_size - minimum size of bounding box for object detected\n",
    "        '''\n",
    "        return self.objectCascade.detectMultiScale(\n",
    "            image,\n",
    "            scaleFactor=scale_factor,\n",
    "            minNeighbors=min_neighbors,\n",
    "            minSize=min_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the resources for frontal face, eye, smile and profile face detection.  \n",
    "\n",
    "Then we initialize the `ObjectDetector` objects defined above with the respective resources, to use CascadeClassifier for each specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frontal face, profile, eye and smile  haar cascade loaded\n",
    "frontal_path = f\"{FACE_DETECTION_FOLDER}/haarcascade_frontalface_default.xml\"\n",
    "eye_path = f\"{FACE_DETECTION_FOLDER}/haarcascade_eye.xml\"\n",
    "profile_path = f\"{FACE_DETECTION_FOLDER}/haarcascade_profileface.xml\"\n",
    "smile_path = f\"{FACE_DETECTION_FOLDER}/haarcascade_smile.xml\"\n",
    "paths_list = [frontal_path, eye_path, profile_path, smile_path]\n",
    "\n",
    "# Detector object created\n",
    "front_d, eye_d, prof_d, smile_d = [ObjectDetector(path) for path in paths_list]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a function for detection and display of all these specific objects.  \n",
    "\n",
    "The function call the **detect** method of the **ObjectDetector** object. For each object we are using a different shape and color, as following:\n",
    "* Frontal face: green rectangle;  \n",
    "* Eye: red circle;  \n",
    "* Smile: red rectangle;  \n",
    "* Profile face: blue rectangle.  \n",
    "\n",
    "Note: due to a huge amount of false positive, we deactivate for now the smile detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image, scale_factor, min_neighbors, min_size):\n",
    "    '''\n",
    "    Objects detection function\n",
    "    Identify frontal face, eyes, smile and profile face and display the detected objects over the image\n",
    "    param: image - the image extracted from the video\n",
    "    param: scale_factor - scale factor parameter for `detect` function of ObjectDetector object\n",
    "    param: min_neighbors - min neighbors parameter for `detect` function of ObjectDetector object\n",
    "    param: min_size - minimum size parameter for f`detect` function of ObjectDetector object\n",
    "    '''\n",
    "    \n",
    "    image_gray=cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    eyes=eye_d.detect(image_gray,\n",
    "        scale_factor=scale_factor,\n",
    "        min_neighbors=min_neighbors,\n",
    "        min_size=(int(min_size[0]/2), int(min_size[1]/2)))\n",
    "\n",
    "    for x, y, w, h in eyes:\n",
    "        #detected eyes shown in color image\n",
    "        cv.circle(image,(int(x+w/2),int(y+h/2)),(int((w + h)/4)),(0, 0,255),3)\n",
    " \n",
    "    # deactivated due to many false positive\n",
    "    #smiles=smile_d.detect(image_gray,\n",
    "    #               scale_factor=scale_factor,\n",
    "    #               min_neighbors=min_neighbors,\n",
    "    #               min_size=(int(min_size[0]/2), int(min_size[1]/2)))\n",
    "\n",
    "    #for x, y, w, h in smiles:\n",
    "    #    #detected smiles shown in color image\n",
    "    #    cv.rectangle(image,(x,y),(x+w, y+h),(0, 0,255),3)\n",
    "\n",
    "\n",
    "    profiles=prof_d.detect(image_gray,\n",
    "        scale_factor=scale_factor,\n",
    "        min_neighbors=min_neighbors,\n",
    "        min_size=min_size)\n",
    "\n",
    "    for x, y, w, h in profiles:\n",
    "        #detected profiles shown in color image\n",
    "        cv.rectangle(image,(x,y),(x+w, y+h),(255, 0,0),3)\n",
    "\n",
    "    faces=front_d.detect(image_gray,\n",
    "        scale_factor=scale_factor,\n",
    "        min_neighbors=min_neighbors,\n",
    "        min_size=min_size)\n",
    "\n",
    "    for x, y, w, h in faces:\n",
    "        #detected faces shown in color image\n",
    "        cv.rectangle(image,(x,y),(x+w, y+h),(0, 255,0),3)\n",
    "\n",
    "    # image\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function extracts an image from a video and then call the function that extracts the face rectangle from the image and display the rectangle above the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_objects(video_file, video_set_folder=TRAIN_SAMPLE_FOLDER):\n",
    "    '''\n",
    "    Extract one image from the video and perform object detection (face, eyes, smile, profile).\n",
    "    '''\n",
    "    video_path = os.path.join(video_set_folder, video_file)\n",
    "\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"❌ File not found: {video_path}\")\n",
    "        return\n",
    "\n",
    "    capture_image = cv.VideoCapture(video_path)\n",
    "    ret, frame = capture_image.read()\n",
    "\n",
    "    if not ret or frame is None:\n",
    "        print(f\"⚠️ Failed to read frame from video: {video_path}\")\n",
    "        capture_image.release()\n",
    "        return\n",
    "\n",
    "    # Optional: convert to RGB if needed later\n",
    "    # frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    detect_objects(image=frame, scale_factor=1.3, min_neighbors=5, min_size=(50, 50))\n",
    "    capture_image.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read meta data into Pandas' DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Loading existing DataFrame from file...\n"
     ]
    }
   ],
   "source": [
    "SAVE_PATH = os.path.join(ROOT_FOLDER, 'meta_df.pkl')\n",
    "\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    print(\"📄 Loading existing DataFrame from file...\")\n",
    "    meta_df = pd.read_pickle(SAVE_PATH)\n",
    "else:\n",
    "    print(\"🚀 Generating DataFrame from source...\")\n",
    "    meta_df = read_meta_from_json(DATA_DIRECTORIES, DATA_FOLDER, COMPRESSED_DATA_FOLDER)\n",
    "    meta_df.to_pickle(SAVE_PATH)\n",
    "    print(f\"💾 DataFrame saved to: {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of videos in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data samples: 119154\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data samples: {len(meta_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full data set exploration\n",
    "\n",
    "1. Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_count('label', 'classes / labels', meta_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use DataLoader to load the videos \n",
    "\n",
    "1. **shuffle:** ON\n",
    "2. **batch size:** 3\n",
    "3. **source:** DATA_FOLDER\n",
    "4. **compressed data:** COMPRESSED_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(VideoDataset(DATA_FOLDER, 'train'), batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress the videos into smaller tensor objects for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 24 processes.\n",
      "Processing 119154 videos. \n",
      "24 chunks with 4964 videos.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool, Manager\n",
    "from preprocessing.compress_videos import process_chunk\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "print(f\"Using {cores} processes.\")\n",
    "print(f\"Processing {meta_df.shape[0]} videos. \\n{cores} chunks with {meta_df.shape[0] // cores} videos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DmlExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort \n",
    "print(ort.get_available_providers())  # Should include 'DirectML'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
